{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650d65cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHyperparameters are model configuration properties that define a model and remain constant during training\\nThey are part of the model design and do not change\\n\\nModel Inputs - train data (this trains the parameters)\\nModel Parameters - found during training (these are learned, e.g., model coefficient and intercept)\\nModel Hyperparameters - part of the model design (e.g., depth of tree, k neighbors)\\n\\nGrid search is a scikit utility that creates a grid of possible values for each hyperparameter, each cell is a candidate model\\ngridsearchcv evaluates each candidate model (using cross validation)\\nIt is computationally very expensive (also actual cost in cloud can be expensive)\\nDoes not differentiate between important and trivial hyperparameters\\n\\nAlternatively, random search of hyperparameter space can be done\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- (5) Hyperparameter Tuning for Classification Models --- #\n",
    "\"\"\"\n",
    "Hyperparameters are model configuration properties that define a model and remain constant during training\n",
    "They are part of the model design and do not change\n",
    "\n",
    "Model Inputs - train data (this trains the parameters)\n",
    "Model Parameters - found during training (these are learned, e.g., model coefficient and intercept)\n",
    "Model Hyperparameters - part of the model design (e.g., depth of tree, k neighbors)\n",
    "\n",
    "Grid search is a scikit utility that creates a grid of possible values for each hyperparameter, each cell is a candidate model\n",
    "gridsearchcv evaluates each candidate model (using cross validation)\n",
    "It is computationally very expensive (also actual cost in cloud can be expensive)\n",
    "Does not differentiate between important and trivial hyperparameters\n",
    "\n",
    "Alternatively, random search of hyperparameter space can be done\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035f8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameter Tuning a Decision Tree Classifier Using Grid Search --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398581c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875b15cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch    Fare  Embarked_C  Embarked_Q  \\\n",
       "0         1       2    1   2.0      1      1  26.000           0           0   \n",
       "1         0       3    1  21.0      0      0   7.925           0           0   \n",
       "2         0       3    1  44.0      0      0   8.050           0           0   \n",
       "3         1       3    0  22.0      0      0   7.750           0           0   \n",
       "4         0       3    0  45.0      1      4  27.900           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic/processed.csv')\n",
    "\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee948d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "Y = titanic_df['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5bdf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_classification(y_test, y_pred):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    \n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Test data count: \", len(y_test))\n",
    "    print(\"accuracy_count: \", num_acc)\n",
    "    print(\"accuracy_score: \", acc)\n",
    "    print(\"precision_score: \", prec)\n",
    "    print(\"recall_score: \", recall)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958000bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search Cross Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We will find the max depth that gives us the best model (one model for each max_depth value)\n",
    "parameters = {'max_depth': [2, 4, 5, 7, 9, 10]}\n",
    "\n",
    "# cv=3: Use 3-fold cross validation to find the best model - split the dataset into 3 parts\n",
    "    # 2 used to train, 1 used to evaluate (cross validation)\n",
    "# return_train_score=True compares models using the default scoring mechanism for this estimator (i.e., accuracy)\n",
    "    # can be configured to use a different scoring mechanism\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), parameters, cv=3, return_train_score=True)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1e6a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'max_depth': 2}\n",
      "Mean Test Score:  0.7803211733036294\n",
      "Rank:  4\n",
      "Parameters:  {'max_depth': 4}\n",
      "Mean Test Score:  0.8084099136730716\n",
      "Rank:  2\n",
      "Parameters:  {'max_depth': 5}\n",
      "Mean Test Score:  0.8119465329991646\n",
      "Rank:  1\n",
      "Parameters:  {'max_depth': 7}\n",
      "Mean Test Score:  0.7926111575234382\n",
      "Rank:  3\n",
      "Parameters:  {'max_depth': 9}\n",
      "Mean Test Score:  0.7750487329434698\n",
      "Rank:  6\n",
      "Parameters:  {'max_depth': 10}\n",
      "Mean Test Score:  0.780293325907361\n",
      "Rank:  5\n"
     ]
    }
   ],
   "source": [
    "# Print results from each model\n",
    "for i in range(6):\n",
    "    print(\"Parameters: \", grid_search.cv_results_['params'][i])    \n",
    "    print(\"Mean Test Score: \", grid_search.cv_results_['mean_test_score'][i])  \n",
    "    print(\"Rank: \", grid_search.cv_results_['rank_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c451d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model using best params\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth']).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce1b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a4bbe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data count:  143\n",
      "accuracy_count:  115\n",
      "accuracy_score:  0.8041958041958042\n",
      "precision_score:  0.8717948717948718\n",
      "recall_score:  0.5964912280701754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c9e2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameter Tuning a Logistic Regression Classifier Using Grid Search --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91158886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.8, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 0.4, 0.8, 1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), parameters, cv=3, return_train_score=True)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c03f344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'C': 0.1, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.7662396732572172\n",
      "Rank:  12\n",
      "Parameters:  {'C': 0.1, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.7838299452334541\n",
      "Rank:  7\n",
      "Parameters:  {'C': 0.4, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.78378353290634\n",
      "Rank:  10\n",
      "Parameters:  {'C': 0.4, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.7785110925461803\n",
      "Rank:  11\n",
      "Parameters:  {'C': 0.8, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.7890652557319223\n",
      "Rank:  1\n",
      "Parameters:  {'C': 0.8, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.785547201336675\n",
      "Rank:  3\n",
      "Parameters:  {'C': 1, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.7873015873015873\n",
      "Rank:  2\n",
      "Parameters:  {'C': 1, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.785547201336675\n",
      "Rank:  3\n",
      "Parameters:  {'C': 2, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.785547201336675\n",
      "Rank:  3\n",
      "Parameters:  {'C': 2, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.785547201336675\n",
      "Rank:  3\n",
      "Parameters:  {'C': 5, 'penalty': 'l1'}\n",
      "Mean Test Score:  0.7837928153717627\n",
      "Rank:  8\n",
      "Parameters:  {'C': 5, 'penalty': 'l2'}\n",
      "Mean Test Score:  0.7837928153717627\n",
      "Rank:  8\n"
     ]
    }
   ],
   "source": [
    "# 12 models given 2 params where 1 param has 2 options and the other has 6 options\n",
    "for i in range(12):\n",
    "    print(\"Parameters: \", grid_search.cv_results_['params'][i])    \n",
    "    print(\"Mean Test Score: \", grid_search.cv_results_['mean_test_score'][i])  \n",
    "    print(\"Rank: \", grid_search.cv_results_['rank_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acda8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(solver='liblinear', penalty=grid_search.best_params_['penalty'], C=grid_search.best_params_['C']).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c01f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d378f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data count:  143\n",
      "accuracy_count:  118\n",
      "accuracy_score:  0.8251748251748252\n",
      "precision_score:  0.8076923076923077\n",
      "recall_score:  0.7368421052631579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8575b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
